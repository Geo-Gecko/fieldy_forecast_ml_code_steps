{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae6fe54",
   "metadata": {},
   "source": [
    "# Description\n",
    "This  script outlines the steps to create a model to identify cashew fields when fed a sample of random fields with various crops. This model methodology is based on labels data obtained from radiant earth foundation for Benin and satellite images obtained from sentinel hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e3ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from os import getcwd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c3db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d76c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "df = pd.read_csv('Cashews_training_data.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ad2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing data\n",
    "df1 = pd.read_csv('Cashews_testing_data.csv')\n",
    "print(df1.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f2fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation data\n",
    "df2 = pd.read_csv('Cashews_validation_data.csv')\n",
    "print(df2.shape)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a63ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell only if you are creating a model that is based on field values and not pixels\n",
    "train_grouped = df.groupby('fid').mean().reset_index()\n",
    "test_grouped = df1.groupby('fid').mean().reset_index()\n",
    "val_grouped = df2.groupby('fid').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_grouped.drop(columns=['label', 'fid', 'row_loc', 'col_loc', 'tile'])\n",
    "X_test = test_grouped.drop(columns=['label', 'fid', 'row_loc', 'col_loc', 'tile'])\n",
    "y_train, y_test = train_grouped[\"label\"], train_grouped[\"label\"]\n",
    "X_val = val_grouped.drop(columns=['label', 'fid', 'row_loc', 'col_loc', 'tile'])\n",
    "y_val = val_grouped[\"label\"]\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Train data shape is {X_train.shape}\\n\",\n",
    "    f\"testing data shape is {X_test.shape}\\n\",\n",
    "    f\"validation data shape is {X_val.shape}\\n\",\n",
    ")\n",
    "\n",
    "train_npy = X_train.to_numpy()\n",
    "test_npy = X_test.to_numpy()\n",
    "val_npy = X_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain = y_train\n",
    "print(\"The initial training labels are \",np.unique(yTrain))\n",
    "yTrain = yTrain - 1\n",
    "print(\"The edited training labels are \",np.unique(yTrain))\n",
    "# yTest = test_npy[:,-1].astype(int)\n",
    "yTest = y_test\n",
    "print(\"The initial testing labels are \",np.unique(yTest))\n",
    "yTest = yTest - 1\n",
    "# yTest = yTest - 1\n",
    "print(\"The edited testing labels are \",np.unique(yTest))\n",
    "yVal = y_val\n",
    "print(\"The initial testing labels are \",np.unique(yVal))\n",
    "yVal = yVal - 1\n",
    "# yTest = yTest - 1\n",
    "print(\"The edited testing labels are \",np.unique(yVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"xTrain shape: \",X_train.shape)\n",
    "print(\"xTest shape: \",X_test.shape)\n",
    "print(\"xVal shape: \",X_val.shape)\n",
    "print(\"yTrain shape: \",yTrain.shape)\n",
    "print(\"yTest shape: \",yTest.shape)\n",
    "print(\"yVal shape: \",yVal.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646b9058",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_npy\n",
    "X_test = test_npy\n",
    "X_val = val_npy\n",
    "print(\"xTrain shape: \",X_train.shape)\n",
    "print(\"xTest shape: \",X_test.shape)\n",
    "print(\"xVal shape: \",X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026fe272",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = 255\n",
    "# Normalise the data\n",
    "xTrain = X_train / max_value\n",
    "xTest = X_test / max_value\n",
    "xVal = X_val/max_value\n",
    "# Reshape the data\n",
    "xTrain = np.reshape(xTrain,(1235,5,12)) #(\"number of rows\", \"number of dates with images\", number of bands per image\")\n",
    "xTest = np.reshape(xTest,(309,5,12))\n",
    "xVal = np.reshape(xVal,(294,5,12))\n",
    "\n",
    "\n",
    "# Print the shape of reshaped data\n",
    "print(\"xTrain:\",xTrain.shape)\n",
    "print(\"xTest:\",xTest.shape)\n",
    "print(\"xVal:\",xVal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d002c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName= \"CNN_cashew_model\" #Specify model name\n",
    "#save the best weights over9the same file with the model name\n",
    "\n",
    "modelpath = f\"{modelName}_bestweights.hdf5\" #the model will be saved in the same folder as where the notebook is\n",
    "checkpoint = ModelCheckpoint(modelpath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max') #max validation accuracy\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "myadam = keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad6cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The parameters used here are obtained from the best performing model as per the keras tuner script output.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(112,2,activation ='relu', input_shape = (5,12)),\n",
    "#     tf.keras.layers.MaxPooling1D(pool_size=2, strides=2),\n",
    "    tf.keras.layers.Conv1D(112,7, activation ='relu'), \n",
    "#     tf.keras.layers.MaxPooling1D(pool_size=2, strides=2),\n",
    "#     tf.keras.layers.Conv1D(32,2, activation ='relu'), \n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2, strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(80, activation ='relu'),\n",
    "    tf.keras.layers.Dense(8, activation ='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', \n",
    "     optimizer = myadam,               \n",
    "              metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e321f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    xTrain,\n",
    "    yTrain,\n",
    "    batch_size=30,\n",
    "    epochs=200,\n",
    "    validation_data=(xTest, yTest), \n",
    "    class_weight = class_weight,\n",
    "    callbacks=callbacks_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe768aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(f\"{modelName}.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e8c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open(f\"{modelName}.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_from_json(loaded_model_json, custom_objects={'KerasLayer': hub.KerasLayer})\n",
    "model.load_weights(f\"{modelName}_bestweights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd286f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(xVal, verbose = 1)\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb333923",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = []\n",
    "for row in predictions:\n",
    "    value = np.argmax(row)\n",
    "    classification.append(valu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f666c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.array(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cMatrix = confusion_matrix(yVal, y_predicted)\n",
    "print(cMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(yVal,y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f901d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(yVal, y_predicted, average=None)\n",
    "f1_score(yVal, y_predicted, average='weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
